{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DROPPED_COLUMNS_001 = ['oper_set_3','temp_fan_inlet','engine_px_ratio','demanded_fan_speed', \n",
    "                       'demanded_corr_fan_speed','px_fan_inlet','px_by_duct','fuel_air_ratio']\n",
    "RENAMING_DICT = {0: \"engine_num\", 1: \"cycle_num\", 2: \"oper_set_1\", 3: \"oper_set_2\", 4: \"oper_set_3\", 5: \"temp_fan_inlet\",\n",
    "                 6: \"temp_lpc_outlet\", 7: \"temp_hpc_outlet\", 8: \"temp_lpt_outlet\", 9: \"px_fan_inlet\", 10: \"px_by_duct\", 11: \"px_hpc_outlet\",\n",
    "                 12: \"phys_fan_speed\", 13: \"phys_core_speed\", 14: \"engine_px_ratio\", 15: \"stat_px_hpc_out\", 16: \"fuel_flow_ratio\", 17: \"corr_fan_speed\",\n",
    "                 18: \"corr_core_speed\", 19: \"bypass_ratio\", 20: \"fuel_air_ratio\", 21: \"bleed_enthalpy\", 22: \"demanded_fan_speed\", 23: \"demanded_corr_fan_speed\",\n",
    "                 24: \"hpt_coolant_bleed\", 25: \"lpt_coolant_bleed\"}\n",
    "FEATURES_TO_SCALE = ['oper_set_1', 'oper_set_2', 'temp_lpc_outlet', 'temp_hpc_outlet', 'temp_lpt_outlet', \n",
    "                     'px_hpc_outlet', 'phys_fan_speed', 'phys_core_speed', 'stat_px_hpc_out', \n",
    "                     'fuel_flow_ratio', 'corr_fan_speed', 'bypass_ratio', 'bleed_enthalpy', \n",
    "                     'hpt_coolant_bleed', 'lpt_coolant_bleed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(train_path: str, test_path: str, rul_path: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    train = pd.read_csv(train_path, sep=\"\\s+\", header=None)\n",
    "    test = pd.read_csv(test_path, sep=\"\\s+\", header=None)\n",
    "    rul = pd.read_csv(rul_path, header=None)\n",
    "    \n",
    "    train.rename(columns=RENAMING_DICT, inplace=True)\n",
    "    test.rename(columns=RENAMING_DICT, inplace=True)\n",
    "    rul.rename(columns={0: \"rul\"}, inplace=True)\n",
    "    \n",
    "    train.drop(columns=DROPPED_COLUMNS_001, inplace=True)\n",
    "    test.drop(columns=DROPPED_COLUMNS_001, inplace=True)\n",
    "    \n",
    "    train['rul'] = train.groupby('engine_num')['cycle_num'].apply(lambda x: x.max() - x).values\n",
    "    train.drop(columns=\"cycle_num\", inplace=True)\n",
    "    test.drop(columns=\"cycle_num\", inplace=True)\n",
    "    \n",
    "    return train, test, rul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_9456\\3794706481.py:14: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  train['rul'] = train.groupby('engine_num')['cycle_num'].apply(lambda x: x.max() - x).values\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_001, test_001, rul_001 = load_and_preprocess_data(\"../CMAPSS Nasa Data set/train_FD001.txt\",\n",
    "                                                        \"../CMAPSS Nasa Data set/test_FD001.txt\",\n",
    "                                                        \"../CMAPSS Nasa Data set/RUL_FD001.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "train_features = train_001.drop(columns=['engine_num', 'rul'])\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "train_001_scaled = pd.DataFrame(train_features_scaled, columns=train_features.columns)\n",
    "train_001_scaled['rul'] = train_001['rul'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    }
   ],
   "source": [
    "# Model Training and Evaluation\n",
    "def train_evaluate_model(X: pd.DataFrame, y: pd.Series) -> Tuple[RandomForestRegressor, dict]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # GridSearchCV for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "    \n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_train_pred = best_rf_model.predict(X_train)\n",
    "    y_test_pred = best_rf_model.predict(X_test)\n",
    "    \n",
    "    results = {\n",
    "        \"Training RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"Training MAE\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"Training R-squared\": r2_score(y_train, y_train_pred),\n",
    "        \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"Test R-squared\": r2_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    return best_rf_model, results, y_test, y_test_pred\n",
    "\n",
    "X = train_001_scaled.drop(columns='rul')\n",
    "y = train_001_scaled['rul']\n",
    "\n",
    "best_model, results, y_test, y_test_pred = train_evaluate_model(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance\n",
      "Training RMSE: 20.83\n",
      "Training MAE: 14.28\n",
      "Training R-squared: 0.91\n",
      "Test RMSE: 41.00\n",
      "Test MAE: 29.29\n",
      "Test R-squared: 0.63\n",
      "Training error (R-squared difference): 0.28\n",
      "The model may be overfitting on the training data.\n"
     ]
    }
   ],
   "source": [
    "# Output Metrics\n",
    "print(\"Random Forest Model Performance\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "# Assessing overfitting or underfitting\n",
    "training_error = np.abs(results[\"Training R-squared\"] - results[\"Test R-squared\"])\n",
    "print(f\"Training error (R-squared difference): {training_error:.2f}\")\n",
    "\n",
    "if training_error < 0.1:\n",
    "    print(\"The model is well-generalized and balanced.\")\n",
    "elif results[\"Training R-squared\"] > results[\"Test R-squared\"]:\n",
    "    print(\"The model may be overfitting on the training data.\")\n",
    "else:\n",
    "    print(\"The model may be underfitting or requires further optimization.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
